{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import platform\n",
    "\n",
    "\n",
    "def rd_ms():\n",
    "    return random.randint(1, 2)\n",
    "\n",
    "\n",
    "def remove_folder(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    else:\n",
    "        raise Exception(f'{path} not exist')\n",
    "\n",
    "\n",
    "def iTs(i: int) -> str:\n",
    "    s = ''\n",
    "    if i < 10:\n",
    "        s += '0'\n",
    "    return s + str(i)\n",
    "\n",
    "def path_exists(path: str) -> bool:\n",
    "    ps = path_separate()\n",
    "    if ps in path:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def files_cleaner(path: str):\n",
    "    if os.path.isdir(path):\n",
    "        remove_folder(path)\n",
    "    os.mkdir(path)\n",
    "\n",
    "def path_separate():\n",
    "    plat = platform.system()\n",
    "    ps = ''\n",
    "    if plat == 'Windows': ps = '\\\\'\n",
    "    else: ps = '/'\n",
    "    return ps\n",
    "\n",
    "\n",
    "class GoogleTrend:\n",
    "    def __init__(self, q: str, dr: list, dev: bool=False, geo='Global'):\n",
    "        self.download_button_selector = 'body > div.trends-wrapper > div:nth-child(2) > div > md-content > div > div > div:nth-child(1) > trends-widget > ng-include > widget > div > div > div > widget-actions > div > button.widget-actions-item.export'\n",
    "\n",
    "        self.url = u'https://trends.google.com.tw/trends/explore'\n",
    "        self.dev = dev\n",
    "        self.geo = geo if geo != 'Global' else ''\n",
    "        self.ps = path_separate() # path_seperate\n",
    "        self.q = q  # query to search\n",
    "        self.dr = dr  # date range\n",
    "        self.env_dir = os.getcwd()\n",
    "        self.platform = platform.system()\n",
    "        self.driver = self._get_driver()\n",
    "        self.main()\n",
    "\n",
    "    def _get_driver(self) -> webdriver.chrome.webdriver.WebDriver:\n",
    "        headless = not self.dev\n",
    "\n",
    "        driver_path = self._get_driver_path()\n",
    "        data_path = self._create_path(f'{self.ps}temp')\n",
    "        data_path += f'{self.ps}{self.q}'\n",
    "\n",
    "        files_cleaner(data_path)\n",
    "\n",
    "        download_prefs = {\n",
    "            'download.default_directory': data_path,\n",
    "            'download.prompt_for_download': False,\n",
    "            'profile.default_content_settings.popups': 0\n",
    "        }\n",
    "\n",
    "        chrome_options = Options()\n",
    "        if headless:\n",
    "            chrome_options.add_argument('--window-size=1440,900')\n",
    "            chrome_options.add_argument('--headless')\n",
    "        chrome_options.add_experimental_option('prefs', download_prefs)\n",
    "        driver = webdriver.Chrome(\n",
    "            executable_path=driver_path,\n",
    "            options=chrome_options\n",
    "        )\n",
    "        driver.set_window_size(1440, 900)\n",
    "        driver.get(self.url)\n",
    "        time.sleep(0.5)\n",
    "        driver.refresh()\n",
    "        return driver\n",
    "\n",
    "    def _create_path(self, path: str):\n",
    "        if not path_exists(path=path):\n",
    "            return path\n",
    "        split_p = path.split(self.ps)\n",
    "        p = f'{self.env_dir}'\n",
    "        for node in split_p:\n",
    "            if not node:\n",
    "                continue\n",
    "            p += f'{self.ps}{node}'\n",
    "            if not os.path.isdir(p):\n",
    "                os.mkdir(p)\n",
    "        return p\n",
    "\n",
    "    def _get_driver_path(self):\n",
    "        path = rf'{self.env_dir}{self.ps}driver{self.ps}chromedriver'\n",
    "        if self.platform == 'Windows': path += '.exe'\n",
    "        elif self.platform == 'Linux': path += '-linux'\n",
    "        return path\n",
    "\n",
    "    def _toPage(self, url):\n",
    "        self.driver.get(url)\n",
    "        time.sleep(rd_ms())\n",
    "\n",
    "    def _download(self):\n",
    "        headless = not self.dev\n",
    "        selector = self.download_button_selector\n",
    "        # download = self.driver.find_element(By.CSS_SELECTOR, selector)\n",
    "        download = self.driver.find_element_by_css_selector(selector)\n",
    "        time.sleep(rd_ms())\n",
    "        download.click()\n",
    "        time.sleep(1)\n",
    "        self._avoid_rewrite()\n",
    "        print(self.driver.current_url)\n",
    "\n",
    "    def _avoid_rewrite(self):\n",
    "        temp_path = f'{self.env_dir}{self.ps}temp{self.ps}{self.q}'\n",
    "        i = 1\n",
    "        while os.path.isfile(f'{temp_path}{self.ps}{i}.csv'): i+= 1\n",
    "        avoid_rewrite_path = f'{temp_path}{self.ps}{i}.csv'\n",
    "        os.rename(f'{temp_path}{self.ps}multiTimeline.csv', avoid_rewrite_path)\n",
    "\n",
    "    def _get_tidy_df_per_day(self):\n",
    "        resolver = DataResolver(self.q)\n",
    "        tidy = resolver.tidy_map\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        for y in tidy.keys():\n",
    "            df[f'{y}'] = [e[2] for e in tidy[y]]\n",
    "            df['M/D'] = [f'{e[0]}-{e[1]}' for e in tidy[y]]\n",
    "        return df.set_index('M/D')\n",
    "\n",
    "    def scrapping_per_week(self, sy: int, ey: int):\n",
    "        geo_query = f'&geo={self.geo}' if self.geo else ''\n",
    "        cy = sy\n",
    "        sm = 1\n",
    "        while cy <= ey:\n",
    "            print(f'\\n正在抓取第 {cy}年 周資料···')\n",
    "            url = f'{self.url}?date={cy}-01-01%20{cy}-12-31&q={self.q}{geo_query}'\n",
    "            self._toPage(url)\n",
    "            time.sleep(1)\n",
    "            self._download()\n",
    "            time.sleep(rd_ms())\n",
    "            cy += 1\n",
    "    \n",
    "    def _merge_per_week(self, sy: int, ey: int):\n",
    "        print(f'\\n正在合併週\b\b資料 ···')\n",
    "        data_path = self._create_path(f'{self.ps}data{self.ps}week{self.ps}{self.q}')\n",
    "        files_cleaner(data_path)\n",
    "        print(f'合併完成 ···\\n目標位置在 {data_path}\\n')\n",
    "        temp_path = f'{self.env_dir}{self.ps}temp{self.ps}{self.q}'\n",
    "        i = 1\n",
    "        cy = sy\n",
    "        while cy <= ey:\n",
    "            f_path = f'{data_path}{self.ps}{cy}.csv'\n",
    "            os.rename(f'{temp_path}{self.ps}{i}.csv', f_path)\n",
    "            cy += 1\n",
    "            i += 1\n",
    "\n",
    "    def scrapping_per_day(self, sy: int, ey: int):\n",
    "        # sy: start year\n",
    "        # ey: end year\n",
    "        # cy: current_year\n",
    "        # sm: start month\n",
    "        # em: end month\n",
    "        # iTs: integer to string\n",
    "\n",
    "        def _0_or_1(i: int) -> str:\n",
    "            return '0' if i == 6 else '1'\n",
    "        geo_query = f'&geo={self.geo}' if self.geo else ''\n",
    "\n",
    "        cy = sy\n",
    "        sm = 1\n",
    "        while cy <= ey:\n",
    "            print(f'\\n正在抓取第 {cy}年 日資料···')\n",
    "            while sm <= 7:\n",
    "                url = f'{self.url}?'\n",
    "                url += f'date={cy}-{iTs(sm)}-01%20{cy}-{iTs(sm+5)}-3{_0_or_1(sm+5)}&q={self.q}{geo_query}'\n",
    "                sm += 6\n",
    "                self._toPage(url)\n",
    "                time.sleep(1)\n",
    "                self._download()\n",
    "                time.sleep(rd_ms())\n",
    "            cy += 1\n",
    "            sm = 1\n",
    "\n",
    "    def _merge_per_day(self):\n",
    "        print(f'\\n正在合併\b\b資料 ···')\n",
    "        data_path = self._create_path(f'{self.ps}data{self.ps}day{self.ps}{self.q}')\n",
    "        files_cleaner(data_path)\n",
    "        print(f'合併完成 ···\\n目標位置在 {data_path}\\n')\n",
    "        data_path += f'{self.ps}{self.q}.csv'\n",
    "\n",
    "        df = self._get_tidy_df_per_day()\n",
    "        df.to_csv(data_path)\n",
    "\n",
    "    def main(self):\n",
    "        start_year = int(self.dr[0])\n",
    "        end_year = int(self.dr[1])\n",
    "\n",
    "        self.scrapping_per_day(start_year, end_year)\n",
    "        self._merge_per_day()\n",
    "        files_cleaner(f'{self.env_dir}{self.ps}temp{self.ps}{self.q}')\n",
    "        self.scrapping_per_week(start_year, end_year)\n",
    "        self._merge_per_week(start_year, end_year)\n",
    "        self.driver.close()\n",
    "\n",
    "# data cleaner\n",
    "class DataResolver:\n",
    "    def __init__(self, q: str):\n",
    "        self.ps = path_separate()\n",
    "        self.env_dir = os.getcwd()\n",
    "        self.root = f'{self.env_dir}{self.ps}temp{self.ps}{q}'\n",
    "        self.valid_int = [str(i) for i in range(10)]\n",
    "        self.tidy_map = self._tidy_list()\n",
    "\n",
    "    def _tidy_list(self) -> dict:\n",
    "        path_list = self._temp_file_mapper()\n",
    "        if len(path_list) == 0:\n",
    "            raise Exception(f'{self.root} 沒有暫存資料')\n",
    "\n",
    "        _tidy = {}\n",
    "        for p in path_list:\n",
    "            csv = pd.read_csv(p)\n",
    "\n",
    "            data = csv['類別：所有類別'][1:]  # not tidy\n",
    "            date = list(data.index)  # not tidy\n",
    "            \n",
    "            tidy_data = self._merge_with_conflict(data=data, date=date)\n",
    "\n",
    "            # int\n",
    "            year = date[1].split('-')[0]\n",
    "\n",
    "            if year in _tidy.keys():\n",
    "                _tidy[year] += tidy_data\n",
    "            else:\n",
    "                _tidy[year] = tidy_data\n",
    "        return _tidy\n",
    "\n",
    "    def _temp_file_mapper(self) -> list:\n",
    "        path = self.root\n",
    "        if not os.path.isdir(path):\n",
    "            raise Exception(f'{path} 路徑不存在')\n",
    "        i = 1\n",
    "        l = []\n",
    "        while os.path.isfile(f'{self.root}{self.ps}{i}.csv'):\n",
    "            l.append(f'{self.root}{self.ps}{i}.csv')\n",
    "            i += 1\n",
    "        return l\n",
    "\n",
    "    def _merge_with_conflict(self, data: list, date: list) -> list:\n",
    "        tidy = []\n",
    "        i = 0\n",
    "        for e, val in zip(date, data):\n",
    "            t = e.split('-')[1:]\n",
    "            month = t[0]\n",
    "            day = t[1]\n",
    "            tidy.append([month, day, int(val)])\n",
    "            if len(date) == 181 and month == '02' and day == '28':\n",
    "                tidy.append(['02', '29', 'NAN'])\n",
    "            i += 1\n",
    "        return tidy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    qs = str(input('請輸入要搜索的關鍵字： 例如 google facebook\\n')).split()\n",
    "    start = str(input('請輸入起始年份 例如：2004\\n'))\n",
    "    end = str(input('請輸入結尾年份 例如：2019\\n'))\n",
    "    start = time.time()\n",
    "    for q in qs:\n",
    "        st = time.time()\n",
    "        print(f'\\n開始抓取 {q} \b趨勢資料···')\n",
    "        google_trend = GoogleTrend(q, [start, end], dev=False)\n",
    "        ed = time.time()\n",
    "        print(f'抓取 {q} 總共花費 {int(ed-st)}')\n",
    "    end = time.time()\n",
    "    print(f'總共花費約 {int(end-start)}')"
   ]
  }
 ]
}